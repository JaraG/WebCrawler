**WEB CRAWLER**
=====================
Мини web-crawler для сайта github.com

На вход программе подаётся файл, в котором перечислены урлы github профилей

Для каждого профиля P из файла определяются

* Логин
* Полное имя
* Компания
* Локация
* Язык программирования, на котором чаще всего пишет P
* название самого популярного репозитория
* кол-во stars в этом репозитории
* основной язык, на котором написан этот репозиторий

Для получения всех этих данных используется API сайта github.com

* *Путь к директории входного файла читается из переменной окружения crawler.fileDirectory*
* *Имя входного файла читается из переменной окружения crawler.fileName*
* Кол-во одновременных запросов, которые может делать web-crawler читается из переменной окружения crawler.maxParallelRequests
* Задержка между последовательными запросами читается из переменной окружения crawler.requestDelayMs
