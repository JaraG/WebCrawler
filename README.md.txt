**WEB CRAWLER**
=====================
Мини web-crawler для сайта github.com

На вход программе подаётся файл, в котором перечислены урлы github профилей
* Путь к директории входного файла читается из переменной окружения crawler.fileDirectory
* Имя входного файла читается из переменной окружения crawler.fileName

Для каждого профиля P из файла определяются

* Логин
* Полное имя
* Компания
* Локация
* Язык программирования, на котором чаще всего пишет P
* название самого популярного репозитория
* кол-во start в этом репозитории
* основной язык, на котором написан этот репозиторий

Для получения всех этих данных используется API сайта github.com
-----------------------------------
* Кол-во одновременных запросов, которые может делать web-crawler читается из переменной окружения crawler.maxParallelRequests
* Задержка между последовательными запросами читается из переменной окружения crawler.requestDelayMs